title: Concept Space vs Action Space
summary: test

In my circles, it's common to say that [the map is not the territory](https://wiki.lesswrong.com/wiki/The_map_is_not_the_territory). That is to say, it's important to note that our representations of objects and the objects themselves are two distinct things. When you don't respect such a distinction, you end up prey to a host of fallacious reasoning. For example, a conniving army general looking to cross a treacherous mountain pass might have the "clever" idea of erasing the marked mountain range from her map. Similarly, I think there is a map/territory error that arises when we assume that just because two things are conceptually similar, they must be solved the same way.

Here's a concrete example of where this confusion might arise: 

First, let's consider the space of things that fall under [time inconsistent preferences](https://en.wikipedia.org/wiki/Dynamic_inconsistency). Like the name suggests, time consistent preferences arise in situations where we make a decision and then, later on, wish we had acted differently. One instance of this is **temporal discounting**, where we see people value the present much more than the future.

Some places where we might exhibit temporal discounting include:

1. A student puts off studying until the last moment. Instead, they choose to read a fun novel in the interim.
2. A partygoer drinks more than they can handle, leaving their future self to deal with the resulting hangover.
3. A dieter opts for yet another dessert during a meal, leaving the exercise for later.

In all three of these cases, there is indeed a commonality we can abstract—a human considers doing X and later regrets it, instead wishing they had done Y. Given our definition for temporal discounting, it *does* make sense to categorize all three cases as such. 

However, does knowing that all three cases are instances of the same category lend itself to a common solution? 

I think the answer is mostly "no", and I'll try to explain why:

First off, what does knowing about the general case of temporal discounting tell us? Well, we know that this whole phenomenon relates to when our future selves regret an action that we take in the present. Maybe we could try to create a heuristic like "When you're about to do something that you're going to regret...don't."

...

That doesn't seem like enough, does it? 

Instead, consider this:

For our student, it might be that our struggling student needs to reexamine their priorities. Perhaps the regret is misplaced and actually doing poorly on the upcoming test isn’t even that big of a deal. Or perhaps our student could rearrange their schedule around and study with a friend to shave off some of the aversion.

For our partygoer, they may want to consider the sort of circumstances which brought them to said party in the first place. Perhaps avoiding certain problematic friends would allow them to sidestep potential binge opportunities entirely. Or perhaps they could stick to non-alcoholic drinks and still have fun at the party.

For the dieter, it could be the case that planning out their meals in advance would allow them to avoid restaurants with unhealthy desserts. Or perhaps filling up before going out to eat with friends can help curb their desire for desserts.

In all three cases, the point I want to get across is that, when looking for a solution, one might consider dramatically different factors, even though all three situations can be part of the same phenomenon. The initial issue here is that temporal discounting is a *descriptive* category, not a prescriptive one. It was designed to help us see a common pattern between different situations, not necessarily act on them accordingly.

I'm not saying we ought not to use descriptive categories when thinking about self-help. However, in these situations where you’ve got a descriptive classification, it’s actually the specific details (and not the ability to recognize that you’re engaging in a more general phenomenon) which provide the most leverage towards solving your problem.

In other words, it's the considerations like "What led me, in this case, to this situation?" rather than "If this is a temporal discounting situation, what do I do?" that lead to the most useful insights.

Caveat: Thinking about the general concept *can* be useful as a springboard for what to do next. 

For example, say you want to start flossing regularly and correctly recognize that you are trying to form a habit. Then, based on what you know about habit formation in general, you would know that you need a strong context cue to start off the habit. From there, you can think about what items in your bathroom or daily routine could act as a good trigger.

(And indeed, this is how some rationality techniques, like [TAPs](https://www.lesswrong.com/posts/v4nNuJBZWPkMkgQRb/making-intentions-concrete-trigger-action-planning),  are created.)

But note that the majority of the work comes after noticing what to do. Once you've identified the template, most of the work comes in putting in the mental effort to fill it out.

A corollary to this distinction is that the factors constraining actionability are much tighter than those which constrain concepts. When we care about finding ways to cluster items such that their solutions are similar, we are importing a bunch of additional real-world constraints. Concepts, on the other hand, live in our head and have no such requirement. As such, we can think of many, many more ways to categorize objects such that they share a common trait. (See, more generally: [overfitting](https://en.wikipedia.org/wiki/Overfitting)). 

* something about how concepts can lead you to *just* categorize, and leave it at that. giving you a sense of false insight.

==============

As a general rule, then, I think it's important to always hone in on the specifics of a situation, even if you recognize a larger pattern. There’s a sort of mental misstep that can happen where being able to simply identify the generalized principle at work could give the false impression that you also know how to solve the problem. And it's this misstep that I want to caution against.

==============

But I still do think that this sort of conceptual muddling can be pernicious, especially in the related case where two tasks seem similar, despite having vastly different effects. So let’s pivot a little bit to a slightly different situation: situations where your brain, when faced with an apparent conceptual similarity, assumes their actionable similarity, and then defaults to the easier one.

For example, Hunting for Practicality is about how, even when we try to internalize advice, it often gets cached in our brains in a way that’s akin to declarative semantic memory—we end up representing how the concepts are linked to each other and perhaps what properties they hold. 

But, really, the information we should be trying to internalize should be procedural in nature—we care about how the advice can actually affect our actions in practice.

The default is to represent the information as a concept map; that’s a rather simple translation of the information presented to you that doesn’t require much additional effort. Trying to actively consider how your future actions will change as a result of heeding the advice in question. 

And in the absence of other factors, the less effortful option wins out.

For second related example, In Defense of the Obvious is about how just receiving advice can set off our brain’s dismissal signals too quickly when it sounds like something we’ve heard a million times before. Yet, the advice is often still valuable even when it pattern matches to “boring” or “obvious”. Overriding the immediate dismissal response and doing the advice anyway is often a better response.

Once again, verifying whether or not you’ve heard such advice before ends up being an easier task than noting the dismissal, filing it away, and then looking into yourself to see if you actually are doing said obvious advice. It is also the more effortful one.

As a third example, consider a student trying to study math. They have a couple of choices: One thing they could do is read through the textbook and trace through the examples, making sure they can follow each step. Or, they could cover up the example problem and try to work through it themselves.

Looking through the textbook can provide the illusion of “exercising your math muscles”, but it’s the actual act of trying to solve problems which improve your ability to solve problems. And of course doing the real math is what’s harder, in terms of time and effort involved.

The issue with all three of these examples seem to be about the mental labels we use. Both the ineffective option and the active option can fall under the same category (e.g. “studying for math”), despite their major differences. 

(The overall pattern here seems to be that of the Recognizing vs Generating distinction: roughly speaking, it’s much more difficult to put the pieces together at first, than to merely verify that the pieces fit.)

One view is that this sort of behavior is an example of self-signaling. After all, it’s much easier to feel productive than to actually be productive. I also think that, on some level, your brain thinks that you really can get all of the same benefits by doing the easier thing. In this case, your brain is hopeful and also wrong.

There are two takeaways here: 

One is the importance of putting in deliberate, mindful effort, a thesis I hope to expound on in a later post.

The second one is perhaps a more familiar variant on the (now) well-worn phrase “the map is not the territory”. In this case, your ontology is not the reality. Inferences you make based on similarities may not transfer to other inferences of a similar type. 

(Aka “Similarity-based connections are not themselves connected by similarities!”)
